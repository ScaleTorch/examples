# To create HPT, run:
# scaletorch login -ki <access_key_id> -ks <access_key_secret>
# scaletorch launch -c hpt.yml

# Name of the workstation - [Optional]
name: my-hpt

# Name of the training script  
entrypoint: train.py

# Name of the requirements file - [Optional]
requirements: requirements.txt

# Search space for Hyper Parameter Tuning. 
# Note: These values will be sent to the entrypoint through argparse
tuning:
  searchSpace:
    batch_size:
      type: choice
      value: [16, 32, 64, 128]
    hidden_size:
      type: choice
      value: [128, 256, 512, 1024]
    lr:
      type: choice
      value: [0.0001, 0.001, 0.01, 0.1]
    momentum:
      type: uniform
      value: [0, 1]

  tuner:                          
    name: TPE                                     
    optimizeMode: maximize     


# Specify what datasets are to be mounted to the workstation
# VirtualMounts need to be created using the web app
virtualMounts:
  - name: xray-dataset
    dest: /mnt/xray-dataset
  
  - name: image-dataset
    unravelArchives: True

# A custom docker image to use with pre-built dependencies - [Optional]
# Note: The working directory of the docker image should contain the entrypoint and requirements specified above
customImage: 
  image: registry/image:tag
  pythonPath: /bin # Path to python/virtualenv location - [Optional]
  credentials:  # [Optional]
    registry: <>
    username: <>
    password: <>

# Location of your source code - [Optional]
# Notes:
# - If the HPT is launched from within a cloned git folder, ScaleTorch will use the details of the repo automatically
# - credentials field should be present in the case of private repos. Go to the following links to get a list of accepted credentials
# - https://scaletorch.gitbook.io/scaletorch-docs/administration-guides/security
# - The root directory of the repo should contain the entrypoint and requirements specified above
codeTransfer:
  type: GITHUB # Can be any one of [GITHUB_PRIVATE, GITHUB, GITLAB_PRIVATE, GITLAB, BITBUCKET_PRIVATE, BITBUCKET, S3, AZURE, GS, GDRIVE, DROPBOX ]
  repo: https://github.com/ScaleTorch/examples.git
  commit: 87bd1949b13db2a6d750dd63c0c61db94352903f # Uses the latest commit of the primary branch by default [Optional]
  # credentials: 
  #   GITHUB_PAT: <Your Github PAT>

# Number of GPUs needed for each trial - [Default=0]
gpusPerTrial: 1

# Maximum number of GPUs that can be provsioned for this HPT - [Default=-1]
maxGpus: 20

# Minimum vCPUs and memory needed for the workstation - [Optional]
minvCPUs: 4
minMemory: 4

# Number of CPU only workstations needed - [Default=0]
# This field needs to be present only when CPU only workstations are needed
# maxCPUWorkers cannot be non-zero when gpuCount is non-zero
maxCPUWorkers: 0

# What CUDA version to use - [Default=latest_cuda_cersion]
# Note: CUDA version will be ignored in the case of CPU only workstations
cuda: 11.6

# Utilize spot instances or not - [Default=False]
useSpot: False

# Artifacts Storage that was registered with the platform - [Optional]
artifactsDestination:
  name: s3-store
  filter: "**" # glob-like filter to select what artifacts need to be stored  [Optional] [Default="**"]

# Override what cloud providers and what GPU Types to be used for this workstation - [Optional] 
# By default scaletorch looks for cheapest compute in all the registered cloud providers
cloudProviders: 
  - name: AWS
    regions:
    - us-east-1

  - name: AZURE
    regions:
    - southcentralus
    
gpuTypes:
  - V100
  - K80


# Choose type of visualisation between TENSORBOARD and AIM - [Optional]
visualisation:
  type: TENSORBOARD
  startWithJob: True # Starts the visualisation server along with the HPT if set to True - [Default=False]

# Maximum cost in USD that the HPT cannot go beyond - [Optional]
maxCost: 50

# Maximum time that the HPT cannot go beyond - [Optional]
maxTime: 1h

# List of commands that need to be run before launching the training script - [Optional]
# Note: Please avoid "sudo" in the commands
preJobCommands: 
  - apt-get update -y
  - apt-get install net-tools -y

# List of commands that need to be run after the training script finishes executing - [Optional]
# Note: Please avoid "sudo" in the commands
postJobCommands: 
  - apt-get update -y
  - apt-get install net-tools -y


# Environment variables to be set on the workstation - [Optional]    
environment:
  YOUR_KEY: YOUR_VALUE