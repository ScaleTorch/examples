# To create experiment, run:
# scaletorch login -ki <access_key_id> -ks <access_key_secret>
# scaletorch launch -c experiment.yml

experiment:
  args:
    epochs: [3]
    lr: [0.0001]
    batch_size: [64]

# Name of the training script
entrypoint: pytorch.py

# Name of the requirements file - [Optional]
requirements: requirements.txt

codeTransfer:
  repo: https://github.com/ScaleTorch/examples.git
  type: GITHUB
  codeDir: samples/xray-classification
  ref: dapp-mlds

# What CUDA version to use - [Default=latest_cuda_cersion]
# Note: CUDA version will be ignored in the case of CPU only workstations
cuda: 11.3
gpusPerTrial: 1
maxGpus: 1
gpuTypes:
  - V100

# Utilize spot instances or not - [Default=False]
useSpot: False

# Artifacts Storage that was registered with the platform - [Optional]
artifactsDestination:
  name: az-store
  filter: "**" # glob-like filter to select what artifacts need to be stored  [Optional] [Default="**"]

# Override what cloud providers and what GPU Types to be used for this workstation - [Optional]
# By default scaletorch looks for cheapest compute in all the registered cloud providers
cloudProviders:
  - name: AWS
    regions:
      - us-east-1

virtualMounts:
  - name: xray-dataset

# Maximum cost in USD that the experiment cannot go beyond - [Optional]
maxCost: 50

# Maximum time that the experiment cannot go beyond - [Optional]
maxTime: ""

environment:
  WANDB_API_KEY: 9075081088eb223891b8d59bc09bb3102f14eb09
  ST_PLATFORM_API: https://dev-api.storch-api.com
